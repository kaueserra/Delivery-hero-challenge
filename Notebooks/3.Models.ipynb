{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pickle\n",
    "from datetime import datetime \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, f1_score ,classification_report \n",
    "from sklearn.ensemble import RandomForestClassifier   \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import cross_val_score  \n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb  \n",
    "from bayes_opt import BayesianOptimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the baseline model ! \n",
    "\n",
    "In order to have a comparison of gain of performance, as we saw on the EDA part, above 5 transactions or less than a month of the last transactions have a higher rate of return, so that simple rule will be our model to beat: \n",
    "\n",
    "Baseline model: \n",
    "\n",
    "is_returning_customer = last_order < 1 month OR total_transaction > 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data  \n",
    "\n",
    "ds1 = pd.read_csv(\"~/Reicarnation-Blues-Book/data/machine_learning_challenge_order_data.csv\",low_memory=False)  \n",
    "\n",
    "ds2 = pd.read_csv(\"~/Reicarnation-Blues-Book/data/machine_learning_challenge_labeled_data.csv\",low_memory=False)  \n",
    "\n",
    "final_ds = pd.read_csv('~/Reicarnation-Blues-Book/data/final_ds.csv')  \n",
    "\n",
    "final_ds  =pd.merge(final_ds,ds2,how='left',on='customer_id')\n",
    "\n",
    "final_ds.index = final_ds.customer_id  \n",
    "\n",
    "final_ds =final_ds.drop('customer_id',axis=1)\n",
    "\n",
    "ds = pd.merge(ds1,ds2,how='left',on='customer_id')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test \n",
    "\n",
    "xtrain = final_ds.drop('is_returning_customer',axis=1)\n",
    "\n",
    "labels = final_ds['is_returning_customer']\n",
    "\n",
    "x, x_val, y, y_val = train_test_split(xtrain,labels,test_size=0.2,train_size=0.8)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.25,train_size =0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline train f1_score Score ->  79.09664364819078\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Baseline f1_score Score ->  78.95948340836406\n"
     ]
    }
   ],
   "source": [
    "# Calculating the baseline model \n",
    "\n",
    "pred_train_baseline = np.where( (x_train['less_one_month_order_1'] ==1) |( x_train['total_transac_bigger_5_1']==1 ),1,0) \n",
    "\n",
    "print(\"Baseline train f1_score Score -> \",f1_score(pred_train_baseline, y_train,average='micro')*100) \n",
    "\n",
    "print('-*-'*20) \n",
    "\n",
    "pred_test_baseline = np.where( (x_test['less_one_month_order_1'] ==1) |( x_test['total_transac_bigger_5_1']==1 ),1,0) \n",
    "\n",
    "print(\"Baseline f1_score Score -> \",f1_score(pred_test_baseline, y_test,average='micro')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling as the categories as unbalanced \n",
    "\n",
    "sm = SMOTE(random_state=42) \n",
    "\n",
    "x_train_res, y_train_res = sm.fit_resample(x_train, y_train) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models! \n",
    "\n",
    "I will create try three of them without tunning, and the winner I will tune the hyperparameters, I will keep all the hyperparameters in the default mode, only the number of trees and max_iter I will set to 1000  \n",
    " - logistic regression in case the f1 is similar among the models,  \n",
    "    it will be great due its interpretation  \n",
    " - Random Forest, great general algorithm, does not overfit with pruned branches and it is solid \n",
    " - XGBoost, the microsoft version, the lightgbm as it is faster and equally or more accurate  \n",
    " \n",
    " https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score:  0.8297990896547688\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "LR test F1 Score ->  83 2\n"
     ]
    }
   ],
   "source": [
    "# Let's start with the simpler model, logistic regression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"Cross Val Score: \",cross_val_score(lr,x_train,y_train, scoring='f1_micro',cv=5).mean())\n",
    "print('-*-'*20)\n",
    "#predictions_test_lr = lr.predict(x_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "#print(\"LR test F1 Score -> \",round(f1_score(predictions_test_lr, y_test,average='micro')*100),2)\n",
    "\n",
    "print('-*-'*20) \n",
    "\n",
    "predictions_test_lr = lr.predict(x_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"LR test F1 Score -> \",round(f1_score(predictions_test_lr, y_test,average='micro')*100),2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "RF val F1 Score ->  99 2\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "RF test F1 Score ->  82 2\n"
     ]
    }
   ],
   "source": [
    "# Second Model to test is the solid Randon Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf.fit(x_train,y_train)\n",
    "#print(\"Cross Val Score: \",cross_val_score(rf,x_train_res,y_train_res, scoring='f1_weighted',cv=5).mean())\n",
    "print('-*-'*20)\n",
    "\n",
    "\n",
    "predictions_train_RF = rf.predict(x_train)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"RF train F1 Score -> \",round(f1_score(predictions_train_RF, y_train,average='micro')*100),2)\n",
    "\n",
    "\n",
    "print('-*-'*20)\n",
    "\n",
    "\n",
    "predictions_test_RF = rf.predict(x_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"RF test F1 Score -> \",round(f1_score(predictions_test_RF, y_test,average='micro')*100),2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF val F1 Score ->  87 2\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "RF test F1 Score ->  83 2\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n"
     ]
    }
   ],
   "source": [
    "# Last but not least the Light XGBoot  \n",
    "\n",
    "lgbm = lgb.LGBMClassifier(\n",
    "    num_iterations =1000,\n",
    ") \n",
    "\n",
    "lgbm.fit(x_train,y_train) \n",
    "\n",
    "\n",
    "predictions_train_lgbm = lgbm.predict(x_train)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"RF train F1 Score -> \",round(f1_score(predictions_train_lgbm, y_train,average='micro')*100),2) \n",
    "\n",
    "print('-*-'*20)\n",
    "\n",
    "\n",
    "predictions_test_lgbm = lgbm.predict(x_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"RF test F1 Score -> \",round(f1_score(predictions_test_lgbm, y_test,average='micro')*100),2) \n",
    "\n",
    "print('-*-'*20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# LightGBM barely outperformed the baseline model,   \n",
    "as it there was no prunning or minimal leave size, Random Forest overfitted a bit, \n",
    "So I will do a mini hypeparameter search to find the optial parameters \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=3, random_seed=6,n_estimators=10000, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgb_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf,min_sum_hessian_in_leaf,subsample):\n",
    "        params = {'application':'binary', 'metric':'auc'}\n",
    "        params['learning_rate'] = max(min(learning_rate, 1), 0)\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['max_bin'] = int(round(max_depth))\n",
    "        params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n",
    "        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n",
    "        params['subsample'] = max(min(subsample, 1), 0)\n",
    "        \n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "     \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.01, 1.0),\n",
    "                                            'num_leaves': (24, 80),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (5, 30),\n",
    "                                            'max_bin':(20,90),\n",
    "                                            'min_data_in_leaf': (20, 80),\n",
    "                                            'min_sum_hessian_in_leaf':(0,100),\n",
    "                                           'subsample': (0.01, 1.0)}, random_state=200)\n",
    "\n",
    "    \n",
    "    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n",
    "    \n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    model_auc=[]\n",
    "    for model in range(len( lgbBO.res)):\n",
    "        model_auc.append(lgbBO.res[model]['target'])\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(x, y, init_round=5, opt_round=10, n_folds=3, random_seed=6,n_estimators=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.8333129803667263,\n",
       " 'feature_fraction': 0.7175451796385642,\n",
       " 'learning_rate': 0.06082589049721443,\n",
       " 'max_bin': 87,\n",
       " 'max_depth': 25,\n",
       " 'min_data_in_leaf': 63,\n",
       " 'min_sum_hessian_in_leaf': 32.902989847268,\n",
       " 'num_leaves': 30,\n",
       " 'subsample': 0.2623276224265793}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params[1]['num_leaves'] = int(round(opt_params[1]['num_leaves'])) \n",
    "opt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))  \n",
    "opt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin'])) \n",
    "opt_params[1]['min_data_in_leaf'] = int(round(opt_params[1]['min_data_in_leaf'])) \n",
    "\n",
    "opt_params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7175451796385642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7175451796385642\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=63, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=63\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=32.902989847268, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=32.902989847268\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8333129803667263, subsample=0.2623276224265793 will be ignored. Current value: bagging_fraction=0.8333129803667263\n",
      "RF train F1 Score ->  84 2\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "RF test F1 Score ->  84 2\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n"
     ]
    }
   ],
   "source": [
    "lgbm = lgb.LGBMClassifier( num_iterations =1000,\n",
    "    **opt_params[1]\n",
    ") \n",
    "\n",
    "lgbm.fit(x_train,y_train) \n",
    "\n",
    "\n",
    "predictions_test_lgbm = lgbm.predict(x_test)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"RF test F1 Score -> \",round(f1_score(predictions_test_lgbm, y_test,average='micro')*100),2) \n",
    "\n",
    "print('-*-'*20)\n",
    "\n",
    "\n",
    "predictions_val_lgbm = lgbm.predict(x_val)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"RF val F1 Score -> \",round(f1_score(predictions_val_lgbm, y_val,average='micro')*100),2) \n",
    "\n",
    "print('-*-'*20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Step!\n",
    "As the model looks stable I will train with the whole data in order to put inside a pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8333129803667263,\n",
       "               feature_fraction=0.7175451796385642,\n",
       "               learning_rate=0.06082589049721443, max_bin=87, max_depth=25,\n",
       "               min_data_in_leaf=63, min_sum_hessian_in_leaf=32.902989847268,\n",
       "               num_iterations=1000, num_leaves=30,\n",
       "               subsample=0.2623276224265793)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = lgb.LGBMClassifier( num_iterations =1000,\n",
    "    **opt_params[1]\n",
    ") \n",
    "\n",
    "lgbm.fit(xtrain,labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(lgbm, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model2.pkl'\n",
    "\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(lr, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
